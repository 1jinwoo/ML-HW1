{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import random\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import MLE_classifier as mle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('hw1data/propublicaTrain.csv')\n",
    "test = pd.read_csv('hw1data/propublicaTest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4.3 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def preprocess(df):\n",
    "    '''Remove c_charge_degree_M column due to redunduncy'''\n",
    "    return df.drop(labels=['c_charge_degree_M'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_bayes_train(df, features, target='two_year_recid', k=1):\n",
    "    \"\"\"returns class conditional probability distribution and class prior as dictionaries\"\"\"\n",
    "    # initialize variables\n",
    "    sample_size, feature_dim = df.shape[0], len(features)\n",
    "    # print('sample_size, feature_dim: ', sample_size, feature_dim)\n",
    "    y_count = {} # {key = label : value = count of label in sample},\n",
    "    x_count = {} # dict of dicts of dicts = {key=label:value={key=feature:value={key=feature_val:value=count}}}\n",
    "    feature_given_class = {} # Pr[X=x|Y=y]\n",
    "    class_prior = {} # Pr[Y=y]\n",
    "    \n",
    "    # initialize dictionary keys\n",
    "    for label in df[target].unique():\n",
    "        y_count[label], class_prior[label] = 0, 0\n",
    "        x_count[label], feature_given_class[label] = {}, {}\n",
    "        for feature in features:\n",
    "            x_count[label][feature], feature_given_class[label][feature] = {}, {}\n",
    "    \n",
    "    # print('y_count: ', y_count)\n",
    "    # print('x_count: ', x_count)\n",
    "    \n",
    "    # update dictionary values\n",
    "    for index, row in df.iterrows():\n",
    "        label = row[target]\n",
    "        y_count[label] += 1\n",
    "        for feature in features:\n",
    "            feature_val = row[feature]\n",
    "            if feature_val in x_count[label][feature].keys():\n",
    "                x_count[label][feature][feature_val] += 1\n",
    "            else:\n",
    "                x_count[label][feature][feature_val] = 1\n",
    "    \n",
    "    # print('y_count: ', y_count)\n",
    "    # print('x_count: ', x_count)\n",
    "    \n",
    "    # find class prior probabilities\n",
    "    for label in class_prior.keys():\n",
    "        class_prior[label] = y_count[label]/sample_size\n",
    "    \n",
    "    # find feature given class probabilities with additive smoothing\n",
    "    for label in feature_given_class.keys():\n",
    "        for feature in feature_given_class[label].keys():\n",
    "            for feature_val in x_count[label][feature].keys():\n",
    "                feature_given_class[label][feature][feature_val] = \\\n",
    "                (x_count[label][feature][feature_val] + k) / (y_count[label] + k * feature_dim)\n",
    "    # print('class prior: ', class_prior)\n",
    "    # print('f|c: ', feature_given_class)\n",
    "    return class_prior, feature_given_class, y_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(series, features, class_prior, feature_given_class, y_count, k=1):\n",
    "    \"\"\"given a series, return a belief distribution over possible labels\"\"\"\n",
    "    belief = {}\n",
    "    for label in class_prior.keys():\n",
    "        prob = class_prior[label]\n",
    "        for feature in features:\n",
    "            feature_val = series[feature]\n",
    "            # print(feature, feature_val)\n",
    "            if feature_val in feature_given_class[label][feature]:\n",
    "                prob *= feature_given_class[label][feature][feature_val]\n",
    "            else:\n",
    "                prob *= k/(y_count[label] + k * len(features))\n",
    "        belief[label] = prob\n",
    "    return belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(df, features, class_prior, feature_given_class, y_count, target = 'two_year_recid'):\n",
    "    total_pred, accurate_pred = 0, 0\n",
    "    y_preds = []\n",
    "    for index, row in df.iterrows():\n",
    "        y = row[target]\n",
    "        belief = predict(row, features, class_prior, feature_given_class, y_count)\n",
    "        y_pred = max(belief.items(), key=operator.itemgetter(1))[0]\n",
    "        total_pred += 1\n",
    "        if y_pred == y:\n",
    "            accurate_pred += 1\n",
    "        y_preds.append(y_pred)\n",
    "    y_pred_df = pd.DataFrame({'prediction': y_preds})\n",
    "    df = pd.concat([df, y_pred_df], axis=1)\n",
    "    accuracy = accurate_pred/total_pred\n",
    "    return accuracy, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_naive_bayes(train, test):\n",
    "    train = preprocess(train)\n",
    "    test = preprocess(test)\n",
    "    features = list(train)[1:]\n",
    "    class_prior, feature_given_class, y_count = naive_bayes_train(train, features)\n",
    "    return evaluate(test, features, class_prior, feature_given_class, y_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normed Distance\n",
    "def distance(x,y,p):\n",
    "    if (p=='inf'):\n",
    "        all_dist = np.zeros(np.shape(x)[0])\n",
    "        for i in range(np.shape(x)[0]):\n",
    "            all_dist[i] = abs(x[i]-y[i])\n",
    "        return np.amax(all_dist)\n",
    "    else:\n",
    "        sum = 0\n",
    "        for i in range(np.shape(x)[0]):\n",
    "            sum += (abs(x[i]-y[i]))**p\n",
    "        return sum**(1/p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_knn(train, test):\n",
    "    #Training-Validation Split\n",
    "    raw_train_labels=np.array(train['two_year_recid'])\n",
    "    raw_train_input = np.array([np.array(train['sex']),np.array(train['age']),\n",
    "                                np.array(train['race']),np.array(train['juv_fel_count']),\n",
    "                                np.array(train['juv_misd_count']),np.array(train['juv_other_count']),\n",
    "                                np.array(train['priors_count']),np.array(train['c_charge_degree_F'])])\n",
    "    validation_pct = 20\n",
    "    val_size = validation_pct*len(raw_train_labels)//100\n",
    "    val_ind = random.sample(range(len(raw_train_labels)), val_size)\n",
    "    validation_input = np.zeros((8,val_size))\n",
    "    validation_labels = np.zeros(val_size)\n",
    "    training_input = np.zeros((8,len(raw_train_labels)-val_size))\n",
    "    training_labels = np.zeros(len(raw_train_labels)-val_size)\n",
    "    cat_names = ['sex','age','race','juv_fel_count','juv_misd_count','juv_other_count','priors_count','c_charge_degree_F']\n",
    "    val_cnt = 0\n",
    "    trn_cnt = 0\n",
    "    for i in range(len(raw_train_labels)):\n",
    "        if i in val_ind:\n",
    "            for j in range(len(cat_names)):\n",
    "                validation_input[j,val_cnt]=train[cat_names[j]].iloc[i]\n",
    "            validation_labels[val_cnt]=train['two_year_recid'].iloc[i]\n",
    "            val_cnt += 1\n",
    "        else:\n",
    "            for j in range(len(cat_names)):\n",
    "                training_input[j,trn_cnt]=train[cat_names[j]].iloc[i]\n",
    "            training_labels[trn_cnt]=train['two_year_recid'].iloc[i]\n",
    "            trn_cnt += 1\n",
    "    \n",
    "    #Reading in Test Data\n",
    "    test_labels = np.array(test['two_year_recid'])\n",
    "    test_input = np.array([np.array(test['sex']),np.array(test['age']),np.array(test['race']),\n",
    "                           np.array(test['juv_fel_count']),np.array(test['juv_misd_count']),\n",
    "                           np.array(test['juv_other_count']),np.array(test['priors_count']),\n",
    "                           np.array(test['c_charge_degree_F'])])\n",
    "    \n",
    "    #Running the best model, based on validation data, on our testing data\n",
    "    k_final=15\n",
    "    p_final=1\n",
    "    pred_test_labels = np.zeros(len(test_labels))\n",
    "    for i in range(len(test_labels)):\n",
    "        all_distances = np.zeros(len(training_labels))\n",
    "        for j in range(len(training_labels)):\n",
    "            all_distances[j]=distance(test_input[:,i],training_input[:,j],p_final)\n",
    "        ind = np.argpartition(all_distances,k_final)[:k_final]\n",
    "        nearest_labels = [training_labels[temp] for temp in ind]\n",
    "        pred_test_labels[i] = stats.mode(nearest_labels, axis=None)[0][0]\n",
    "    num_correct = 0\n",
    "    for ent in range(len(test_labels)):\n",
    "        if (test_labels[ent]==pred_test_labels[ent]):\n",
    "            num_correct += 1\n",
    "    ACCURACY = num_correct/len(test_labels)*100\n",
    "    TEST_PRED_LIST = pred_test_labels\n",
    "    \n",
    "    # clean up and return\n",
    "    predictions = pd.DataFrame({'prediction': TEST_PRED_LIST})\n",
    "    df = pd.concat([test, predictions], axis=1)\n",
    "    return ACCURACY, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 Which classifier is better for this prediction task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 200, 463, 926, 1389, 1852, 2315, 2778, 3241, 3704, 4167]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define numbers of training samples we are interested in\n",
    "training_samples_nums = [100,200]\n",
    "l = [463*i for i in range(1,10)]\n",
    "training_samples_nums = training_samples_nums + l\n",
    "training_samples_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_nums = [100, 200, 463, 926, 1389, 1852, 2315, 2778, 3241, 3334]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_accuracies = []\n",
    "mle_accuracies = []\n",
    "knn_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "463\n",
      "926\n",
      "1389\n",
      "1852\n",
      "2315\n",
      "2778\n",
      "3241\n",
      "3704\n",
      "4167\n"
     ]
    }
   ],
   "source": [
    "# find accuracies of classifiers\n",
    "for number in training_samples_nums:\n",
    "    print(number)\n",
    "    new_train = train.sample(number)\n",
    "    mle_accuracy, _ = mle.perform_mle(new_train, test)\n",
    "    mle_accuracies.append(mle_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "463\n",
      "926\n",
      "1389\n",
      "1852\n",
      "2315\n",
      "2778\n",
      "3241\n",
      "3704\n",
      "4167\n"
     ]
    }
   ],
   "source": [
    "for number in training_samples_nums:\n",
    "    print(number)\n",
    "    new_train = train.sample(number)\n",
    "    bayes_accuracy, _ = perform_naive_bayes(new_train, test)\n",
    "    bayes_accuracies.append(bayes_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "463\n",
      "926\n",
      "1389\n",
      "1852\n",
      "2315\n",
      "2778\n",
      "3241\n",
      "3704\n",
      "4167\n"
     ]
    }
   ],
   "source": [
    "for number in training_samples_nums:\n",
    "    print(number)\n",
    "    new_train = train.sample(number)\n",
    "    knn_accuracy, _ = perform_knn(new_train, test)\n",
    "    knn_accuracies.append(bayes_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6875,\n",
       " 0.6875,\n",
       " 0.6875,\n",
       " 0.6875,\n",
       " 0.6875,\n",
       " 0.6875,\n",
       " 0.6875,\n",
       " 0.6875,\n",
       " 0.6875,\n",
       " 0.6875,\n",
       " 0.6875,\n",
       " 0.6875,\n",
       " 0.6875]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (11,) and (13,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-a44697facff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_samples_nums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbayes_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_samples_nums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmle_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_samples_nums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3238\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3239\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3240\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3241\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3242\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1709\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1710\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 243\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (11,) and (13,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a13ef0b00>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_samples_nums, bayes_accuracies, '.-')\n",
    "plt.plot(training_samples_nums, mle_accuracies, '.-')\n",
    "plt.plot(training_samples_nums, knn_accuracies, '.-')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
